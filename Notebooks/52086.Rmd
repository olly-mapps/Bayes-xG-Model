---
title: "52086"
output:
  html_document:
    df_print: paged
    toc: yes
---

# README

Our data can be found [here](https://www.kaggle.com/datasets/aleespinosa/soccer-match-event-dataset).

We only used a select number of files, and they are in the Data.zip file attached with the submission. The size of the csv files were very large, and hence the reason for compressing it.

Included in my submission is the file structure used throughout the research, and if Data.zip is unzipped where it is the following notebook will compile.


# Libraries

```{r}
library(tidyverse)
library(MASS)
library(rstanarm)
library(data.table)
library(ggsoccer)
library(jsonlite)
library(gridExtra)
library(stringi)
library(rstan)
library(bayesplot)
library(rstanarm)
library(caret)
```

We also run the following code for making the usage of `rstan` easier later on.

```{r}
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# Data Loading

We first want to load in the events data, which split across multiple csv files, grouped by country. To read this in, I have defined a loop that iterates through the data directory and appends each file to a data-frame.

```{r}
#Define Data Directory
dir_path <- "../Data/events"

#Get a list of files in the directory
file_list <- list.files(dir_path)

#Create an empty data frame to store the file contents
actions <- data.frame()

#Loop through the files and add their contents to the data frame
for (i in 1:length(file_list)) {
  #Read the file into a data frame
  file_data <- fread(file.path(dir_path, file_list[i]))
  
  #Add the file data to the main data frame
  actions <- rbind(actions, file_data)
}
```

```{r}
#View the events data frame
actions
```

We next want to load in the player data

```{r}
#Read in data
players <- fromJSON("../Data/players/players.json")
```

```{r}
#View player data
players
```

Since the event data contains all sorts of event types, we now want to filter out only the shots.

```{r}
# Extract observations of shots from the actions data 
shots_df <- actions %>% dplyr::filter(subEventName == "Shot")
```

## Event Data

The next section is dedicated to loading the event data

### Categorical Data

We now use documentation from [here](https://dataglossary.wyscout.com/shot/) to mutate the data, and garner more useful categorical data about the shot itself.

```{r}
shots_df <- shots_df %>% 
  
  #If the shot is successful
  mutate('is_goal' = ifelse(grepl(" 101}", shots_df$tags),1,0), 
         
         #If the shot is at the end of a counter-attack
         'is_CA' = ifelse(grepl(" 1901}", shots_df$tags),1,0),
         
         #If the shot is with the foot or another part of the body
         'body_part' = ifelse(grepl(" 401}", shots_df$tags),"left",
                              ifelse(grepl(" 402}", shots_df$tags), "right", 
                                   ifelse(grepl(" 403}", shots_df$tags), "body", "NA"))),
         
         #If the shot is blocked
         'is_blocked' = ifelse(grepl(" 2101}", shots_df$tags), 1,0))

#Filter out only unblocked shots
shots_df <- shots_df %>% dplyr::filter(is_blocked == 0)

#Keep necessary categorical data
shots_cat <- dplyr::select(shots_df, c('playerId', 'is_goal', 'is_CA', 'body_part'))

summary(shots_cat)
```

### Positional Data

We now calculate the distance from the goal and angle to goal for each shot.

First, we would like to define the position of each shot on the pitch

```{r}
#Extract all numeric entries from the positions column
pos <- str_extract_all(gsub('"', "", shots_df$positions), "\\d+")

#Define vectors to store coordinates
x_pos <- c()
y_pos <- c()

#Loops that extract the coordinates
for (i in 1:length(pos)){
  x_pos <- append(x_pos, pos[[i]][2])
}

for (i in 1:length(pos)){
  y_pos <- append(y_pos, pos[[i]][1])
}

#Convert coordinates to numeric data
x_pos <- x_pos %>% as.numeric()
y_pos <- y_pos %>% as.numeric()
```

```{r}
# Create coordinate dataframe
coords <- data.frame(x_pos, y_pos)
```

We can now use these coordinates to calculate distance and angle to goal

```{r}
#Define length and width of pitch

pitch_x <- 105
pitch_y <- 68

#We now convert coordinates to meters
x_meter <- coords$x_pos * pitch_x/100
y_meter <- coords$y_pos * pitch_y/100

# Calculate distances
dist <- sqrt((105 - x_meter)^2 + ((32.5) - y_meter)^2)

#Calculate angles
angles <- atan( (7.32 * (105 - x_meter) ) / ( (105 - x_meter)^2 + (32.5 - y_meter)^2 - (7.32/2)^2 )) * 180/pi
```

We can now merge our useful event data into one data-frame.

```{r}
#Concatenate data-frames
shots <- data.frame(shots_cat, dist, angles)
```

## Player Data

The next section is dedicated to loading the player data. For this, we simply filter only by the features that will prove useful later on.

First lets retrieve a vector of all unique players in the current `shots` data-base:

```{r}
#Retrieves unique player ids
player_list <- unique(shots$playerId)
```

We can now filter the `players` data-frame to only include these players

```{r}
#Filters by player ids between both data frames
shooters <- dplyr::filter(players, wyId %in% player_list)
```

We can filter this data-frame by the features we need.

```{r}
#Selects necessary columns
shooters <- dplyr::select(shooters, c('shortName', 'wyId', 'foot'))
```

Finally, we rename the some columns, for ease later on.

```{r}
#Renames columns
colnames(shooters)[colnames(shooters) == "wyId"] <- "playerId"
colnames(shooters)[colnames(shooters) == "foot"] <- "preferred_foot"
```

### Preferred Foot Data

We will now introduce a preferred foot binary variable.

First we merge all our useful data into one data-frame

```{r}
#Concatenate data-frames
shots <- merge(shots, shooters, by = "playerId")
```

We now mutate this to add a column featuring the desired binary variable

```{r}
#Adds preferred foot binary column
shots <- shots %>% 
  mutate(preferred_foot_b = ifelse(shots$preferred_foot == shots$body_part, 1, 0))
```

Finally, we remove the `preferred_foot` column

```{r}
#Removes desired column
shots <- shots %>% dplyr::select(-c("preferred_foot"))
```

## Data Cleaning/Wrangling

Since much of our data is categorical, it is necessary to convert it to the factor type.

```{r}
#Convert necessary variables to factor 

shots$body_part <- shots$body_part %>% as.factor()

shots$is_CA <- shots$is_CA %>% as.factor()

shots$preferred_foot_b <- shots$preferred_foot_b %>% as.factor()

shots$shortName <- shots$shortName %>% as.factor()
```

Now lets view a summary of our data

```{r}
summary(shots)
```

### Player Names

If we view a random subset of our data, we observe a problem decoding unicode characters:

```{r}
shots[90:100,]
```

So we use the following chunk to decode them

```{r}
shots$shortName <- stringi::stri_unescape_unicode(shots$shortName)
```

### Negative Angles

We can see from the summary there are negative angles in the data, to investigate this further we can look at a histogram

```{r}
hist(shots$angles)
```

We observe that there are multiple negative angles. Since most of the angles are correctly positive, we will remove the negative ones from the analysis.

```{r}
shots <- shots %>% dplyr::filter(shots$angles > 0)
```

To see the corrected histogram

```{r}
hist(shots$angles)
```

### Player Downsampling

Later on we will use `playerId` to group the data. Since our data-set is large and spans many countries, there are many different players in the data-set

```{r}
length(table(shots$playerId))
```

We see there are 2292 unique player included in the data-set

With this in hand, it would be sensible to limit the amount of "groups" (players) to, say 50. In order to preserve the greatest amount of data, we will use the top 50 most occurring player names.

```{r}
top_players <- sort(table(shots$playerId), decreasing = T)[1:50]
```

Now we filter the data based on these players

```{r}
top_shots <- dplyr::filter(shots, playerId %in% row.names(top_players))
```

### Numbering Of Players

In some of our later models, it is necessary to number the players from 1 to 50. This step is carried out below.

```{r}
top_shots$bayes_id <- as.numeric(as.factor(top_shots$shortName))
```

We can now view a summary of our final data 

```{r}
summary(top_shots)
```

# Data Exploration

To better understand our distance and angle data, we can create the following boxplots.

```{r}
#Defines and distance boxplot

dist_boxplot <- ggplot(top_shots, aes(x=is_goal, y=dist, fill = as.factor(is_goal))) + 
                geom_boxplot() +
                labs(title="Distributions Of Distances Grouped By Shot Outcome", 
                     x="Shot Outcome", 
                     y="Distance To Goal (m)") + 
                coord_flip()

dist_boxplot <- dist_boxplot + guides(fill=guide_legend(title="Goal (1) or Not (0)"))

#Defines angles boxplot

angles_boxplot <- ggplot(top_shots, aes(x=is_goal, y=angles, fill = as.factor(is_goal))) + 
                  geom_boxplot() + 
                  labs(title="Distributions Of Angles Grouped By Shot Outcome", 
                     x="Shot Outcome", 
                     y="Angle To Goal (Degrees)") +
                  coord_flip()

angles_boxplot <- angles_boxplot + guides(fill=guide_legend(title="Goal (1) or Not (0)"))

#Plots distance boxplot
dist_boxplot
```
```{r}
#Plots angles boxplot
angles_boxplot
```
From these we observe there must is likely some relationship between the outcome of a shot and the position from which it is taken.

Next, in order to motivate prior elicitation, we consider the distribution of our most important parameters.

```{r}
dist_dist <- ggplot(top_shots, aes(x=dist)) + 
                geom_histogram(fill = "#00BFC4") +
                labs(title="Distributions Of Distances", 
                     x="Distance (m)", 
                     y="Volume") 

dist_dist
```
```{r}
angle_dist <- ggplot(top_shots, aes(x=angles)) + 
                geom_histogram(fill = "#00bfc4") +
                labs(title="Distributions Of Angles", 
                     x="Angle (Degrees)", 
                     y="Volume") 

angle_dist
```




We now visualise the frequency at which each player takes a shot, and its corresponding success

Firstly, we need to wrangle the data a bit more:

```{r}
#Create data-frame from top_players table defined earlier
top_players_df <- data.frame(top_players)

#Rename columns
colnames(top_players_df)[colnames(top_players_df) == "Var1"] <- "playerId"
colnames(top_players_df)[colnames(top_players_df) == "Freq"] <- "shotVolume"

#We add a column containing player name
top_players_df <- merge(top_players_df, distinct(top_shots[, c("playerId", "shortName")]), by = "playerId")

#We create a dataframe where the is_goal variable is numeric
numeric_goals <- top_shots[, c("shortName", "is_goal")]
numeric_goals$is_goal <- as.numeric(as.character(numeric_goals$is_goal))

#We sum up goals scored by player
summed_goals <- numeric_goals %>%
  group_by(shortName) %>% 
  summarise(goals = sum(is_goal))

#Merge to final data-frame
shots_goals <- merge(top_players_df, summed_goals, by = "shortName") 

#Sort in descending order by shot volume
shots_goals <- arrange(shots_goals, desc(shotVolume))
shots_goals$shortName <- shots_goals$shortName %>% as.factor()
```

Now we visualise the results

```{r width = 5}

#Converts the data into a readable format for ggplot
shots_goals_long <- gather(shots_goals, key = var, value = value, shotVolume, goals)

#Creates the plot structure
shots_goals_plot <- ggplot(shots_goals_long, aes(x=reorder(shortName, -value), y = value, fill = var)) +
                    geom_col(position = "identity", width = 0.9) +
                    labs(title="Shots And Goals By Player", 
                     x="Players", 
                     y="Volume") +
                    scale_x_discrete(guide = guide_axis(angle = 60))

#Adds a legend
shots_goals_plot <- shots_goals_plot + guides(fill=guide_legend(title="Key"))

#Plot
shots_goals_plot
                    
```

We can see from the plot, that there is some difference in a players ability to convert a shot. We can exploit this difference by adding another level to our models.

```{r}
top_shots
```

# Fitting Models

## Data Splitting

Since our data-set is somewhat small, it would be wise to have an uneven split of test and train data. This is carried out in the following chunk.

```{r}
# Split into test and train subsets
train.size <- 0.8 * nrow(top_shots) 
train <- sample(1:nrow(top_shots), train.size)
test <- -train
shots.train <- top_shots[train, ]
shots.test <- top_shots[test, ]
is_goal.test <-  top_shots$is_goal[test]
```

## Non-Baysian Models

First we will fit some simple logistic regression models.

### `is_goal` ~ `dist` 

First we fit a model based on just distance.

```{r}
glm1 <- glm(is_goal ~ dist, data = shots.train, family = binomial())

summary(glm1)
confint(glm1)
```
We see that our confidence intervals are quite small already.

```{r}
#Make predictions
probs_1 <- predict(glm1, data = shots.test, type = "response")

#Convert probabilities to binary predictions
predictions_1 <- ifelse(probs_1 > 0.5, 1, 0)

#Calculate accuracy
accuracy_1 <- mean(predictions_1 == is_goal.test)

#Output accuracy
accuracy_1
```
We also a achieve a test accuracy of 81.5%.

### `is_goal` ~ `dist` + `angles`

```{r}
glm2 <- glm(is_goal ~ dist + angles, data = shots.train, family = binomial())

summary(glm2)
confint(glm2)
```
Again we are our confidence intervals are quite small, this is beginning to imply we have sufficient data to make reasonable predictions.

```{r}
#Make predictions
probs_2 <- predict(glm2, data = shots.test, type = "response")

#Convert probabilities to binary predictions
predictions_2 <- ifelse(probs_2 > 0.5, 1, 0)

#Calculate accuracy
accuracy_2 <- mean(predictions_2 == is_goal.test)

#Output Accuracy
accuracy_2
```
Interestingly, our predictive accuracy has decreased, but not by an overly significant amount.

### `is_goal` ~ `.`

We finally fit a model with all the relevant predictors, this is primarily to motivate variable selection later on.

```{r}
glm3 <- glm(is_goal ~ . - shortName - playerId - bayes_id, data = shots.train, family = binomial())

summary(glm3)
```
We observe from this final fit, that due to their low p-values, `angles`, `dist`, and `body_part` are the most important variables when determining the outcome of a shot.

```{r}
probs_3 <- predict(glm3, data = shots.test, type = "response")

# Convert probabilities to binary predictions
predictions_3 <- ifelse(probs_3 > 0.5, 1, 0)

# Calculate accuracy
accuracy_3 <- mean(predictions_3 == is_goal.test)

accuracy_3
```
Once again, interestingly our predictive accuracy has decreased again.


## Bayesian Linear Regression 

In this section we fit our Bayesian models.

### Single-Level Models

#### `is_goal` ~ `dist`

We next fit our single level Bayesian models, and produce helpful figures

```{r}
#Creates a design matrix for stan
bmod1_X <- model.matrix(is_goal ~ dist, data = shots.train)
```

```{r}
#Creates a design matrix for predictions
bmod1_X_new <- model.matrix(is_goal ~ dist, data = shots.test)

#Defines stan list
bmod1_list <- list(y = as.numeric(as.character(shots.train$is_goal)),
                 n = dim(shots.train)[1],
                 p=2,
                 X = bmod1_X,
                 
                 #Predictive Inputs
                 n_new = dim(shots.test)[1],
                 X_new = bmod1_X_new,
                 
                 #Prior parameters
                 beta_mu = 19,
                 beta_sigma = 10)

#Runs Stan
bmod1 <- stan(file = "../Stan Files/dist.stan", data = bmod1_list, chains = 4, iter = 1000, init = 0, seed = 1)
          
```

```{r}
print(bmod1, pars="beta")
```
We observe that our confidence intervals have not changed much, which implies our injection of information is not making much difference.

We also observe a high n_eff and Rhat, which means our models are converging well.

```{r}
plot(bmod1, pars="beta")
```
Here is a visualisation of the confidence intervals on our beta.

```{r}
traceplot(bmod1, pars='beta')
```
We also observe that our traceplots are not varying much with each chain, implying good convergence.

```{r}
#Extract fit
ext_fit_1 <- extract(bmod1)

#Calculate accuracy
mean(apply(ext_fit_1$y_new, 2, median) == is_goal.test)
```
We observe a higher prediction accuracy than in the baselines, but by a marginal amount.

Further graphs used in report can be found in shinystan

```{r}
#launch_shinystan(bmod1)
```

#### `is_goal` ~ `dist` + `body_part`

```{r}
#Creates design matrix for training and testing
bmod2_X <- model.matrix(is_goal ~ dist + body_part, data = shots.train)

bmod2_X_new <- model.matrix(is_goal ~ dist + body_part, data = shots.test)

#Defines list for stan
bmod2_list <- list(y = as.numeric(as.character(shots.train$is_goal)),
                 n = dim(shots.train)[1],
                 X = bmod2_X,
                 p = 4,
                 
                 #Predictive Parameters
                 n_new = dim(shots.test)[1],
                 X_new = bmod2_X_new,
                 
                 #Prior Parameters
                 beta_mu_dist = 19,
                 beta_sigma_dist = 10
                 )

#Runs stan
bmod2 <- stan(file = "../Stan Files/dist+body.stan", data = bmod2_list, chains = 4, init = 0, seed = 1)
```

```{r}
print(bmod2, pars="beta")
```
We again observe no significant change in the confidence intervals, and again a high n_eff and Rhat.

```{r}
plot(bmod2, pars="beta")
```
Here we observe the confidence intervals once again have not changed a significant amount.

```{r}
traceplot(bmod2, pars='beta')
```
As before our traceplots demonstrate good convergence.

```{r}
#Extract posterior from stan
ext_fit_2 <- extract(bmod2)

#Calculate accuracy
mean(apply(ext_fit_2$y_new, 2, median) == is_goal.test)
```
We observe a marginally higher test accuracy once again.

Further plots used in report can be found in shinystan

```{r}
#launch_shinystan(bmod2)
```

#### `is_goal` ~ `dist` + `body_part` + `angles`

We finally fit a Bayesian model using the most important variables.

```{r}
#Creates Design Matrices
bmod3_X <- model.matrix(is_goal ~ dist + body_part + angles, data = shots.train)

bmod3_X_new <- model.matrix(is_goal ~ dist + body_part + angles, data = shots.test)
```

```{r}
#Defines list for stan
bmod3_list <- list(y = as.numeric(as.character(shots.train$is_goal)),
                 n = dim(shots.train)[1],
                 X = bmod3_X,
                 p = 5,
                 
                 #Predictive Parameters
                 n_new = dim(shots.test)[1],
                 X_new = bmod3_X_new,
                 
                 #Prior Parameters
                 beta_mu_dist = 19,
                 beta_sigma_dist = 10,
                 
                 beta_mu_angle = 30,
                 beta_sigma_angle = 10
                 )


#Runs Stan
bmod3 <- stan(file = "../Stan Files/dist+angles+body.stan", data = bmod3_list, chains = 4, init = 0, seed = 1)
```

```{r}
print(bmod3, pars="beta")
```

Once again, it appears our confidence intervals have not changed by any significant amount. Further, our n_eff and Rhat statistics are showing good signs of convergence.

```{r}
plot(bmod3, pars="beta")
```

```{r}
traceplot(bmod3, pars='beta')
```

We again see good convergence properties in our traceplots.

```{r}
#Extract fit
ext_fit_3 <- extract(bmod3)

#Calculate accuracy
mean(apply(ext_fit_3$y_new, 2, median) == is_goal.test)
```
We observe a once again a slightly higher predictive accuracy.

Further plots used in report can be found in shinystan.

```{r}
#launch_shinystan(bmod3)
```

### Heirarchical Models 

In the final section, we fit our multi-level model, which aims to take into account the variation between player abilities.

#### `is_goal` ~ `distance` + (1 | `shortName`)

```{r}
#Defines list for stan
bhmod1_list <- list(y = as.numeric(as.character(shots.train$is_goal)),
                 n = dim(shots.train)[1],
                 X = shots.train$dist,
                 
                 #Defines Grouping
                 players = length(unique(shots.train$bayes_id)),
                 player = shots.train$bayes_id,
                 
                 #Predictive Inputs
                 n_new = dim(shots.test)[1],
                 X_new = shots.test$dist,
                 
                 #Hyper-Prior Parameters
                 #alpha_mu_mu = 30,
                 #alpha_mu_sigma = 10,
                 #alpha_sigma_rate = 10,
                 
                 beta_mu_mu = 19,
                 beta_mu_sigma = 10,
                 beta_sigma_rate = 10
                 )

#Runs stan
bhmod1 <- stan(file = "../Stan Files/dist+shortName.stan", data = bhmod1_list, chains = 4, init = 0, seed = 1)
```

```{r}
print(bhmod1, pars="beta")
```
Despite the warning in the sampling, our n_eff and Rhat statistics show good convergence. So taking advice from [here](https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup), we can safely ignore these divergent chains and use our model. Rhat and n_eff is also good for alpha, which can be found in shinystan.

We observe once again that our confidence intervals have not changed a great deal, however this was not the purpose of this final model. We aimed to take into account player variation, which the following plot proves we have, as discussed in the report.

```{r}
#launch_shinystan(bhmod1)
```

We next visualise a prediction of the model, to emphasies how this new model now considers player abilities.

```{r}
#Extracts generated quantities
ext_fit_4 <- extract(bhmod1)

#Constructs a data-frame
salah_pp <- data.frame(Population = ext_fit_4$pp_y_new, MohamedSalah = ext_fit_4$salah_y_new)

#Makes the data-frame readable to ggplot
salah_pp <- reshape2::melt(salah_pp)

#Constructs the plot
salah_pp_plot <- ggplot(salah_pp, aes(x=value, fill=variable)) +
                  geom_density(alpha=.25) +
                  labs(title="xG Plot Of The Population And Mohamed Salah", 
                     x="xG", 
                     y="Likelihood") 

#Adds Legend
salah_pp_plot <- salah_pp_plot + guides(fill=guide_legend(title="Key"))

#Plots
salah_pp_plot
```


