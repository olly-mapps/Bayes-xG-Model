---
title: "Sandbox"
output: html_notebook
---

#Libraries
```{r}
library(tidyverse)
library(dplyr)
library(MASS)
library(rstanarm)
library(ggplot2)
library(data.table)
```

# Data Loading

```{r}
#Read in data
actions <- fread('../Data/actions.csv', header=TRUE)
 
#Obtain summary data
summary(actions)
```
```{r}
# Extract observations of shots from the actions data 
shots_df <- actions %>% dplyr::filter(type_name == "shot")
```

```{r}
# Keep only necessary features
shots <- dplyr::select(shots_df, c('result_id','bodypart_id', 'bodypart_name'))

coords <- dplyr::select(shots_df, c('start_x','start_y','end_x',
                            'end_y'))
shots
```

## Calculate Distance and Angle to goal
```{r}
#Define position of goal

GOAL_X = 0
GOAL_Y = 68 / 2

#Define differences for for calculations 
diff <- data.frame(abs(GOAL_X - coords$start_x), 
                   abs(GOAL_Y - coords$start_y))

# Calculate distances
dist <- data.frame(sqrt(diff[1]**2 + diff[2]**2))

ifelse(diff$ != 0, 
                         my_data$numerator / my_data$denominator, 
                         0)
```
```{r}
#Concatenate dataframes
shots <- data.frame(shots, dist)

shots
```

```{r}
#Convert variables to factor 

shots <- shots %>% mutate_if(is.integer,as.factor)
```

```{r}
dim(shots)
```
We observe from the above chunk that we have almost 300,000 observations, this could prove lengthy to fit a bayesian model to later on. Further, the `radon.csv` file used in lectures comparatively only has 1,000 observations. As such, I believe it suitable to randomly subsample about 20,000 observations.

```{r}
shots_sub <- shots %>% sample_n(1000)
dim(shots_sub)
```

```{r}
shots_sub
```

```{r}
# Split into test and train subsets
train.size <- nrow(shots_sub) / 2
train <- sample(1:nrow(shots_sub), train.size)
test <- -train
shots.train <- shots_sub[train, ]
shots.test <- shots_sub[test, ]
is_goal.test <-  shots_sub$is_goal[test]
```

# Data Exploration

**Insert Exploration Here If Necessary Later**

# Fitting Models

## Simple Logistic Regression 

```{r}
#Fit Logistic Regression
glm.fit <- glm(is_goal ~ location+bodypart, family = "binomial", data = shots.train)

#Calculate mis-classification
glm.probs <-  predict(glm.fit, shots.test, type = "response")
glm.pred <-  rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] <- 1

mean(glm.pred != is_goal.test)
```
## Bayesian Logistic Regression

### Bayesian Model 1 (location and bodypart)

```{r}
#Fit the model
bmod1 = stan_glm(is_goal~ location+bodypart ,data=shots.train, family = binomial)
```
```{r}
#Model Summary
bmod1
```

```{r}
#Summary data on the priors
prior_summary(bmod)
```
```{r}
#Retrieve and print posterior interval for the model
ci95_1 <- posterior_interval(bmod1, prob = 0.95)
round(ci95_1, 2)
```
```{r}
#Launch shinystan
launch_shinystan(bmod1, ppd = FALSE)
```
```{r}
#Calculate misclassification
bmod1.pred <-  posterior_predict(bmod1, shots.test, type = "response")

mean(bmod1.pred != is_goal.test)
```
### Bayesian Model 2 (location and bodypart as heirarchical variable)

```{r}
bmod2 = stan_glmer(is_goal ~ location+(1 | bodypart) ,data=shots.train, family = binomial)
```
```{r}
bmod2.pred <-  posterior_predict(bmod2, shots.test, type = "response")

mean(bmod2.pred != is_goal.test)
```

